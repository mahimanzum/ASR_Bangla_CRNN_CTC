{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "GS2gKYgOuJYG",
    "outputId": "dbdfc6a2-ad01-4c0b-837f-a892286194d1"
   },
   "outputs": [],
   "source": [
    "!wget http://www.openslr.org/resources/53/asr_bengali_0.zip\n",
    "\n",
    "!wget http://www.openslr.org/resources/53/asr_bengali_1.zip\n",
    "!wget http://www.openslr.org/resources/53/asr_bengali_2.zip\n",
    "!wget http://www.openslr.org/resources/53/asr_bengali_3.zip\n",
    "!wget http://www.openslr.org/resources/53/asr_bengali_4.zip\n",
    "!wget http://www.openslr.org/resources/53/asr_bengali_5.zip\n",
    "!wget http://www.openslr.org/resources/53/asr_bengali_6.zip\n",
    "\n",
    "!wget http://www.openslr.org/resources/53/asr_bengali_7.zip\n",
    "!wget http://www.openslr.org/resources/53/asr_bengali_8.zip\n",
    "!wget http://www.openslr.org/resources/53/asr_bengali_9.zip\n",
    "!wget http://www.openslr.org/resources/53/asr_bengali_a.zip\n",
    "!wget http://www.openslr.org/resources/53/asr_bengali_b.zip\n",
    "!wget http://www.openslr.org/resources/53/asr_bengali_c.zip\n",
    "!wget http://www.openslr.org/resources/53/asr_bengali_d.zip\n",
    "!wget http://www.openslr.org/resources/53/asr_bengali_e.zip\n",
    "\n",
    "!wget http://www.openslr.org/resources/53/asr_bengali_f.zip\n",
    "!wget http://www.openslr.org/resources/53/utt_spk_text.tsv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "pBpDpRG_bnk-",
    "outputId": "4e4a4089-957a-478b-e902-9c7d22137d5f"
   },
   "outputs": [],
   "source": [
    "!unzip -o asr_bengali_0.zip\n",
    "!sudo rm -rf asr_bengali_0.zip\n",
    "\n",
    "!unzip -o asr_bengali_1.zip\n",
    "!sudo rm -rf asr_bengali_1.zip\n",
    "\n",
    "!unzip -o asr_bengali_2.zip\n",
    "!sudo rm -rf asr_bengali_2.zip\n",
    "\n",
    "!unzip -o asr_bengali_3.zip\n",
    "!sudo rm -rf asr_bengali_3.zip\n",
    "\n",
    "!unzip -o asr_bengali_4.zip\n",
    "!sudo rm -rf asr_bengali_4.zip\n",
    "\n",
    "!unzip -o asr_bengali_5.zip\n",
    "!sudo rm -rf asr_bengali_5.zip\n",
    "\n",
    "!unzip -o asr_bengali_6.zip\n",
    "!sudo rm -rf asr_bengali_6.zip\n",
    "\n",
    "!unzip -o asr_bengali_7.zip\n",
    "!sudo rm -rf asr_bengali_7.zip\n",
    "\n",
    "!unzip -o asr_bengali_8.zip\n",
    "!sudo rm -rf asr_bengali_8.zip\n",
    "\n",
    "!unzip -o asr_bengali_9.zip\n",
    "!sudo rm -rf asr_bengali_9.zip\n",
    "\n",
    "!unzip -o asr_bengali_a.zip\n",
    "!sudo rm -rf asr_bengali_a.zip\n",
    "\n",
    "!unzip -o asr_bengali_b.zip\n",
    "!sudo rm -rf asr_bengali_b.zip\n",
    "\n",
    "!unzip -o asr_bengali_c.zip\n",
    "!sudo rm -rf asr_bengali_c.zip\n",
    "\n",
    "!unzip -o asr_bengali_d.zip\n",
    "!sudo rm -rf asr_bengali_d.zip\n",
    "\n",
    "!unzip -o asr_bengali_e.zip\n",
    "!sudo rm -rf asr_bengali_e.zip\n",
    "\n",
    "!unzip -o asr_bengali_f.zip\n",
    "!sudo rm -rf asr_bengali_f.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rNK56AgbzxMA"
   },
   "outputs": [],
   "source": [
    "#ls asr_bengali/data/0f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2oADFdBLsLeM"
   },
   "outputs": [],
   "source": [
    "#df.loc[3][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2F0uBsHBcGF4"
   },
   "outputs": [],
   "source": [
    "#from glob import glob\n",
    "#audio_files = glob(\"asr_bengali/data/*/*.flac\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "cyHRPdgndaF4",
    "outputId": "9314a521-1d9b-4c80-aee4-c51dc7d3338c"
   },
   "outputs": [],
   "source": [
    "#print(audio_files[-1])\n",
    "#len(audio_files)\n",
    "!git clone https://github.com/NVIDIA/apex\n",
    "!cd apex;pip install -v --no-cache-dir ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gS8L2bWDFQAg"
   },
   "outputs": [],
   "source": [
    "from apex import amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 720
    },
    "colab_type": "code",
    "id": "3HSXjgzQCrzi",
    "outputId": "9fbf4f21-a117-42fb-c2a3-f8b1d4c40d5d"
   },
   "outputs": [],
   "source": [
    "!pip install soundfile\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv('utt_spk_text.tsv', sep=\"\\t\", header = None)\n",
    "df.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "_B-79tqAhcSz",
    "outputId": "f37b5354-4bc5-4668-c3d7-0722644cf28d"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import isdir, join\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Math\n",
    "import numpy as np\n",
    "from scipy.fftpack import fft\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import librosa\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import IPython.display as ipd\n",
    "import librosa.display\n",
    "\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3fB-O2giw3UA"
   },
   "outputs": [],
   "source": [
    "import albumentations\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import ImageFile\n",
    "import soundfile as sf  \n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "SEED = 1234\n",
    "import random\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "\n",
    "def pad_sequences(x, max_len):\n",
    "    #print(x)\n",
    "    padded = torch.zeros((max_len), dtype=torch.long)\n",
    "    if len(x) > max_len: padded[:] = torch.tensor(x[:max_len] , dtype=torch.long)\n",
    "    else: padded[:len(x)] = torch.tensor(x, dtype=torch.long)\n",
    "    return padded\n",
    "\n",
    "class ASRDataset(Dataset):\n",
    "    def __init__(self, image_paths, targets, resize=(75, 300)):\n",
    "        # resize = (height, width)\n",
    "        self.image_paths = image_paths\n",
    "        self.targets = targets\n",
    "        self.resize = resize\n",
    "\n",
    "\n",
    "\n",
    "        mean = (0.485, 0.456, 0.406)\n",
    "        std = (0.229, 0.224, 0.225)\n",
    "        self.aug = albumentations.Compose(\n",
    "            [\n",
    "                albumentations.Normalize(\n",
    "                    mean, std, max_pixel_value=255.0, always_apply=True\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def log_specgram(self, audio, sample_rate, window_size=20,\n",
    "                 step_size=10, eps=1e-10):\n",
    "        #print(\"in log function \", type(sample_rate))\n",
    "        #print(sample_rate)\n",
    "        nperseg = int(round(window_size * sample_rate / 1e3))\n",
    "        noverlap = int(round(step_size * sample_rate / 1e3))\n",
    "        freqs, times, spec = signal.spectrogram(audio,\n",
    "                                        fs=sample_rate,\n",
    "                                        window='hann',\n",
    "                                        nperseg=nperseg,\n",
    "                                        noverlap=noverlap,\n",
    "                                        detrend=False)\n",
    "        return freqs, times, np.log(spec.T.astype(np.float32) + eps)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        #image = Image.open(self.image_paths[item]).convert(\"RGB\")\n",
    "        samples, sample_rate = sf.read(self.image_paths[item]) \n",
    "        #print(type(samples))\n",
    "        #print(samples.shape)\n",
    "\n",
    "        #print(type(sample_rate))\n",
    "        #print(sample_rate)\n",
    "\n",
    "        #freqs, times, spectrogram = self.log_specgram(samples, sample_rate)\n",
    "        \n",
    "        #mean = np.mean(spectrogram, axis=0)\n",
    "        #std = np.std(spectrogram, axis=0)\n",
    "        #spectrogram = (spectrogram - mean) / std\n",
    "        S = librosa.feature.melspectrogram(samples, sr=sample_rate, n_mels=128)\n",
    "\n",
    "        # Convert to log scale (dB). We'll use the peak power (max) as reference.\n",
    "        log_S = librosa.power_to_db(S, ref=np.max)\n",
    "        log_S = (log_S-np.mean(log_S, axis=0))/np.std(log_S, axis=0)\n",
    "\n",
    "\n",
    "        image = Image.fromarray(log_S , 'L').convert(\"RGB\")\n",
    "\n",
    "        targets = self.targets[item]\n",
    "\n",
    "        if self.resize is not None:\n",
    "            image = image.resize(\n",
    "                (self.resize[1], self.resize[0]), resample=Image.BILINEAR\n",
    "            )\n",
    "\n",
    "        image = np.array(image)\n",
    "        #augmented = self.aug(image=image)\n",
    "        #image = augmented[\"image\"]\n",
    "        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n",
    "\n",
    "        #print(targets)\n",
    "\n",
    "        return {\n",
    "            \"images\": torch.tensor(image, dtype=torch.float),\n",
    "            \"targets\": torch.tensor(pad_sequences(targets, 20), dtype=torch.long),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 117,
     "referenced_widgets": [
      "9a11aa20369644e6a9d665ea1e453b00",
      "9f0ca46e517b4bceb75b031cd3787dab",
      "184d0db66ccc4e3e9c1bad1627d905b3",
      "a5c924ac95d24ce893e4e5487c9f3211",
      "26a5cf89a6ee421693847c4b94b16d91",
      "ee34d2d990674dc493c371cd539c4d87",
      "7904ddfb5f4749ab936c54d96dfc9c1d",
      "323ff2342e3843ada30bb9ae5f07098b"
     ]
    },
    "colab_type": "code",
    "id": "cmnm6II1zJwU",
    "outputId": "1aa0347c-9a16-441a-8736-4214483122e1"
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "img_paths = []\n",
    "targets = []\n",
    "print(len(df))\n",
    "\n",
    "for idx in tqdm(range(len(df))):\n",
    "  pth = \"asr_bengali/data/\"+df.loc[idx][0][:2]+'/'+df.loc[idx][0]+'.flac'\n",
    "  if os.path.exists(pth):\n",
    "    img_paths.append(pth)\n",
    "    targets.append(df.loc[idx][2].strip())\n",
    "print(len(img_paths))\n",
    "print(img_paths[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "rd8kSLtC18gd",
    "outputId": "586ee337-d50a-41ce-9b40-eaf5bd29dc42"
   },
   "outputs": [],
   "source": [
    "print(targets[0])\n",
    "#train_data = ASRDataset()\n",
    "from sklearn import preprocessing\n",
    "targets = [[c for c in x] for x in targets]\n",
    "targets_flat = [c for clist in targets for c in clist]\n",
    "\n",
    "lbl_enc = preprocessing.LabelEncoder()\n",
    "lbl_enc.fit(targets_flat)\n",
    "targets_enc = [lbl_enc.transform(x) for x in targets]\n",
    "targets_enc = np.array(targets_enc)\n",
    "#targets_enc = targets_enc + 1\n",
    "print(targets_enc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rRIDU00OBSTt"
   },
   "outputs": [],
   "source": [
    "train_dataset = ASRDataset(\n",
    "        image_paths=img_paths[:-512],\n",
    "        targets=targets_enc[:-512],\n",
    "    )\n",
    "\n",
    "test_dataset = ASRDataset(\n",
    "        image_paths=img_paths[-512:],\n",
    "        targets=targets_enc[-512:],\n",
    "    )\n",
    "test_targets_orig = targets[-512:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1hnuQro5BSid",
    "outputId": "cd8aeea6-b7bb-421d-9dd3-b58ecd4d1394"
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=128,\n",
    "        num_workers=8,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=128,\n",
    "        num_workers=8,\n",
    "        shuffle=True,\n",
    "    )\n",
    "print(len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "OStP-Cf7Cby9",
    "outputId": "63158913-bc1a-42a9-d2eb-7a2182e2fab6"
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class BeamEntry:\n",
    "\t\"information about one single beam at specific time-step\"\n",
    "\tdef __init__(self):\n",
    "\t\tself.prTotal = 0 # blank and non-blank\n",
    "\t\tself.prNonBlank = 0 # non-blank\n",
    "\t\tself.prBlank = 0 # blank\n",
    "\t\tself.prText = 1 # LM score\n",
    "\t\tself.lmApplied = False # flag if LM was already applied to this beam\n",
    "\t\tself.labeling = () # beam-labeling\n",
    "\n",
    "\n",
    "class BeamState:\n",
    "\t\"information about the beams at specific time-step\"\n",
    "\tdef __init__(self):\n",
    "\t\tself.entries = {}\n",
    "\n",
    "\tdef norm(self):\n",
    "\t\t\"length-normalise LM score\"\n",
    "\t\tfor (k, _) in self.entries.items():\n",
    "\t\t\tlabelingLen = len(self.entries[k].labeling)\n",
    "\t\t\tself.entries[k].prText = self.entries[k].prText ** (1.0 / (labelingLen if labelingLen else 1.0))\n",
    "\n",
    "\tdef sort(self):\n",
    "\t\t\"return beam-labelings, sorted by probability\"\n",
    "\t\tbeams = [v for (_, v) in self.entries.items()]\n",
    "\t\tsortedBeams = sorted(beams, reverse=True, key=lambda x: x.prTotal*x.prText)\n",
    "\t\treturn [x.labeling for x in sortedBeams]\n",
    "\n",
    "\n",
    "def applyLM(parentBeam, childBeam, classes, lm):\n",
    "\t\"calculate LM score of child beam by taking score from parent beam and bigram probability of last two chars\"\n",
    "\tif lm and not childBeam.lmApplied:\n",
    "\t\tc1 = classes[parentBeam.labeling[-1] if parentBeam.labeling else classes.index(' ')] # first char\n",
    "\t\tc2 = classes[childBeam.labeling[-1]] # second char\n",
    "\t\tlmFactor = 0.01 # influence of language model\n",
    "\t\tbigramProb = lm.getCharBigram(c1, c2) ** lmFactor # probability of seeing first and second char next to each other\n",
    "\t\tchildBeam.prText = parentBeam.prText * bigramProb # probability of char sequence\n",
    "\t\tchildBeam.lmApplied = True # only apply LM once per beam entry\n",
    "\n",
    "\n",
    "def addBeam(beamState, labeling):\n",
    "\t\"add beam if it does not yet exist\"\n",
    "\tif labeling not in beamState.entries:\n",
    "\t\tbeamState.entries[labeling] = BeamEntry()\n",
    "\n",
    "\n",
    "def ctcBeamSearch(mat, classes, lm, beamWidth=25):\n",
    "\t\"beam search as described by the paper of Hwang et al. and the paper of Graves et al.\"\n",
    "\n",
    "\tblankIdx = len(classes)\n",
    "\tmaxT, maxC = mat.shape\n",
    "\n",
    "\t# initialise beam state\n",
    "\tlast = BeamState()\n",
    "\tlabeling = ()\n",
    "\tlast.entries[labeling] = BeamEntry()\n",
    "\tlast.entries[labeling].prBlank = 1\n",
    "\tlast.entries[labeling].prTotal = 1\n",
    "\n",
    "\t# go over all time-steps\n",
    "\tfor t in range(maxT):\n",
    "\t\tcurr = BeamState()\n",
    "\n",
    "\t\t# get beam-labelings of best beams\n",
    "\t\tbestLabelings = last.sort()[0:beamWidth]\n",
    "\n",
    "\t\t# go over best beams\n",
    "\t\tfor labeling in bestLabelings:\n",
    "\n",
    "\t\t\t# probability of paths ending with a non-blank\n",
    "\t\t\tprNonBlank = 0\n",
    "\t\t\t# in case of non-empty beam\n",
    "\t\t\tif labeling:\n",
    "\t\t\t\t# probability of paths with repeated last char at the end\n",
    "\t\t\t\tprNonBlank = last.entries[labeling].prNonBlank * mat[t, labeling[-1]]\n",
    "\n",
    "\t\t\t# probability of paths ending with a blank\n",
    "\t\t\tprBlank = (last.entries[labeling].prTotal) * mat[t, blankIdx]\n",
    "\n",
    "\t\t\t# add beam at current time-step if needed\n",
    "\t\t\taddBeam(curr, labeling)\n",
    "\n",
    "\t\t\t# fill in data\n",
    "\t\t\tcurr.entries[labeling].labeling = labeling\n",
    "\t\t\tcurr.entries[labeling].prNonBlank += prNonBlank\n",
    "\t\t\tcurr.entries[labeling].prBlank += prBlank\n",
    "\t\t\tcurr.entries[labeling].prTotal += prBlank + prNonBlank\n",
    "\t\t\tcurr.entries[labeling].prText = last.entries[labeling].prText # beam-labeling not changed, therefore also LM score unchanged from\n",
    "\t\t\tcurr.entries[labeling].lmApplied = True # LM already applied at previous time-step for this beam-labeling\n",
    "\n",
    "\t\t\t# extend current beam-labeling\n",
    "\t\t\tfor c in range(maxC - 1):\n",
    "\t\t\t\t# add new char to current beam-labeling\n",
    "\t\t\t\tnewLabeling = labeling + (c,)\n",
    "\n",
    "\t\t\t\t# if new labeling contains duplicate char at the end, only consider paths ending with a blank\n",
    "\t\t\t\tif labeling and labeling[-1] == c:\n",
    "\t\t\t\t\tprNonBlank = mat[t, c] * last.entries[labeling].prBlank\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tprNonBlank = mat[t, c] * last.entries[labeling].prTotal\n",
    "\n",
    "\t\t\t\t# add beam at current time-step if needed\n",
    "\t\t\t\taddBeam(curr, newLabeling)\n",
    "\t\t\t\t\n",
    "\t\t\t\t# fill in data\n",
    "\t\t\t\tcurr.entries[newLabeling].labeling = newLabeling\n",
    "\t\t\t\tcurr.entries[newLabeling].prNonBlank += prNonBlank\n",
    "\t\t\t\tcurr.entries[newLabeling].prTotal += prNonBlank\n",
    "\t\t\t\t\n",
    "\t\t\t\t# apply LM\n",
    "\t\t\t\tapplyLM(curr.entries[labeling], curr.entries[newLabeling], classes, lm)\n",
    "\n",
    "\t\t# set new beam state\n",
    "\t\tlast = curr\n",
    "\n",
    "\t# normalise LM scores according to beam-labeling-length\n",
    "\tlast.norm()\n",
    "\n",
    "\t # sort by probability\n",
    "\tbestLabeling = last.sort()[0] # get most probable labeling\n",
    "\n",
    "\t# map labels to chars\n",
    "\tres = ''\n",
    "\tfor l in bestLabeling:\n",
    "\t\tres += classes[l]\n",
    "\n",
    "\treturn res\n",
    "\n",
    "def testBeamSearch():\n",
    "\t\"test decoder\"\n",
    "\tclasses = 'ab'\n",
    "\tmat = np.array([[0.4, 0, 0.6], [0.4, 0, 0.6]])\n",
    "\tprint('Test beam search')\n",
    "\texpected = 'a'\n",
    "\tactual = ctcBeamSearch(mat, classes, None)\n",
    "\tprint('Expected: \"' + expected + '\"')\n",
    "\tprint('Actual: \"' + actual + '\"')\n",
    "\tprint('OK' if expected == actual else 'ERROR')\n",
    "\n",
    "\n",
    "testBeamSearch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 120
    },
    "colab_type": "code",
    "id": "icOG9kfkRpGq",
    "outputId": "4d1c3f9f-d2e4-4e36-f332-022dac762de8"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "from tqdm.auto import tqdm\n",
    "import soundfile as sf  \n",
    "def log_specgram(audio, sample_rate, window_size=20,\n",
    "                 step_size=10, eps=1e-10):\n",
    "    #print(\"in log function \", type(sample_rate))\n",
    "    #print(sample_rate)\n",
    "    nperseg = int(round(window_size * sample_rate / 1e3))\n",
    "    noverlap = int(round(step_size * sample_rate / 1e3))\n",
    "    freqs, times, spec = signal.spectrogram(audio,\n",
    "                                    fs=sample_rate,\n",
    "                                    window='hann',\n",
    "                                    nperseg=nperseg,\n",
    "                                    noverlap=noverlap,\n",
    "                                    detrend=False)\n",
    "    return freqs, times, np.log(spec.T.astype(np.float32) + eps)\n",
    "\n",
    "\n",
    "\n",
    "for idx in tqdm(range(len(df))):\n",
    "    pth = \"asr_bengali/data/\"+df.loc[idx][0][:2]+'/'+df.loc[idx][0]+'.flac'\n",
    "    \n",
    "    samples, sample_rate = sf.read(pth) \n",
    "    freqs, times, spectrogram = log_specgram(samples, sample_rate)\n",
    "    #print(spectrogram.shape)\n",
    "    S = librosa.feature.melspectrogram(samples, sr=sample_rate, n_mels=128)\n",
    "\n",
    "    # Convert to log scale (dB). We'll use the peak power (max) as reference.\n",
    "    log_S = librosa.power_to_db(S, ref=np.max)\n",
    "    print((log_S-np.mean(log_S, axis=0))/np.std(log_S, axis=0) )\n",
    "    #mean = np.mean(spectrogram, axis=0)\n",
    "    #std = np.std(spectrogram, axis=0)\n",
    "    #print(mean.shape, std.shape)\n",
    "    break\n",
    "  #spectrogram = (spectrogram - mean) / std\n",
    "\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "DrZBNG_l3NcT",
    "outputId": "d33d8a62-334d-4678-ebee-f0f9102ec7c5"
   },
   "outputs": [],
   "source": [
    "#print(len(lbl_enc.classes_))\n",
    "lbl_enc.transform(lbl_enc.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "TY53GS_P_Dmr",
    "outputId": "b39a6ce1-0ded-4e64-acf6-e9ebb9585384"
   },
   "outputs": [],
   "source": [
    "#s = \"বাংলাদেশে দায়িত্ব নেবে\"\n",
    "#\"\".join(lbl_enc.inverse_transform(lbl_enc.transform([c for c in s])))\n",
    "\"\".join(lbl_enc.inverse_transform(targets_enc[1070]))\n",
    "\n",
    "print(len(lbl_enc.classes_))\n",
    "print(len(\"\".join(lbl_enc.classes_)))\n",
    "print(\"\".join(lbl_enc.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6MdskFtm2mfj"
   },
   "outputs": [],
   "source": [
    "#print(s)\n",
    "#s[127]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R_VP0IHas7fY"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "class ASRModel(nn.Module):\n",
    "    def __init__(self, num_chars):\n",
    "        super(ASRModel, self).__init__()\n",
    "        self.conv_1 = nn.Conv2d(3, 128, kernel_size=(3, 6), padding=(1, 1))\n",
    "        self.pool_1 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "        self.conv_2 = nn.Conv2d(128, 64, kernel_size=(3, 6), padding=(1, 1))\n",
    "        self.pool_2 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "        self.linear_1 = nn.Linear(1152, 64)\n",
    "        self.drop_1 = nn.Dropout(0.2)\n",
    "        self.lstm = nn.GRU(64, 32, bidirectional=True, num_layers=2, dropout=0.1, batch_first=True)\n",
    "        self.output = nn.Linear(64, num_chars + 1)\n",
    "        self.blnk_index = num_chars\n",
    "    def forward(self, images, targets=None):\n",
    "        bs, _, _, _ = images.size()\n",
    "        x = F.relu(self.conv_1(images))\n",
    "        #print(\"model printint start\", x.size())\n",
    "        x = self.pool_1(x)\n",
    "        x = F.relu(self.conv_2(x))\n",
    "        #print(\"line 29\", x.size())\n",
    "        x = self.pool_2(x)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        #print(\"line 29\", x.size())\n",
    "        x = x.view(bs, x.size(1), -1)\n",
    "        #print(\"line 29\", x.size())\n",
    "        x = F.relu(self.linear_1(x))\n",
    "        #print(\"line 29\", x.size())\n",
    "        x = self.drop_1(x)\n",
    "        x, _ = self.lstm(x)\n",
    "        #print(\"line 29\", x.size())\n",
    "        x = self.output(x)\n",
    "        #print(\"line 30\", x.size())\n",
    "        x = x.permute(1, 0, 2)\n",
    "\n",
    "        if targets is not None:\n",
    "            log_probs = F.log_softmax(x, 2)\n",
    "            input_lengths = torch.full(\n",
    "                size=(bs,), fill_value=log_probs.size(0), dtype=torch.int32\n",
    "            )\n",
    "            target_lengths = torch.full(\n",
    "                size=(bs,), fill_value=targets.size(1), dtype=torch.int32\n",
    "            )\n",
    "            loss = nn.CTCLoss(blank=self.blnk_index)( #blank = 0 previously\n",
    "                log_probs, targets, input_lengths, target_lengths\n",
    "            )\n",
    "            return x, loss\n",
    "\n",
    "        return x, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I7pGAdZwBSnU"
   },
   "outputs": [],
   "source": [
    "from apex import amp\n",
    "def train_fn(model, data_loader, optimizer):\n",
    "    model.train()\n",
    "    fin_loss = 0\n",
    "    tk0 = tqdm(data_loader, total=len(data_loader))\n",
    "    for data in tk0:\n",
    "        for key, value in data.items():\n",
    "            #print(key.shape)\n",
    "            #print(value.shape)\n",
    "            data[key] = value.to('cuda')\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out, loss = model(**data)\n",
    "\n",
    "        with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "            scaled_loss.backward()\n",
    "        #loss.backward()\n",
    "        optimizer.step()\n",
    "        fin_loss += loss.item()\n",
    "    return fin_loss / len(data_loader)\n",
    "\n",
    "def eval_fn(model, data_loader):\n",
    "    model.eval()\n",
    "    fin_loss = 0\n",
    "    fin_preds = []\n",
    "    with torch.no_grad():\n",
    "        tk0 = tqdm(data_loader, total=len(data_loader))\n",
    "        for data in tk0:\n",
    "            for key, value in data.items():\n",
    "                data[key] = value.to('cuda')\n",
    "            out, loss = model(**data)\n",
    "\n",
    "            fin_preds.append(out)\n",
    "            '''\n",
    "            preds = out.permute(1, 0, 2)\n",
    "            preds = torch.softmax(preds, 2).detach().cpu().numpy()\n",
    "            print(preds[0].shape)\n",
    "            print(\"predicted = \",ctcBeamSearch(preds[0], \"\".join(lbl_enc.classes_), None))\n",
    "            print(\"actual output = \",\"\".join(lbl_enc.inverse_transform(data['targets'][0].detach().cpu().numpy()) )) \n",
    "            '''\n",
    "            fin_loss += loss.item()\n",
    "            \n",
    "    return fin_preds, fin_loss / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ObUEjNy5jBjW"
   },
   "outputs": [],
   "source": [
    "def remove_duplicates(x):\n",
    "    if len(x) < 2:\n",
    "        return x\n",
    "    fin = \"\"\n",
    "    for j in x:\n",
    "        if fin == \"\":\n",
    "            fin = j\n",
    "        else:\n",
    "            if j == fin[-1]:\n",
    "                continue\n",
    "            else:\n",
    "                fin = fin + j\n",
    "    return fin\n",
    "\n",
    "\n",
    "def decode_predictions(preds, encoder):\n",
    "    preds = preds.permute(1, 0, 2)\n",
    "    preds = torch.softmax(preds, 2)\n",
    "    preds = torch.argmax(preds, 2)\n",
    "    preds = preds.detach().cpu().numpy()\n",
    "    cap_preds = []\n",
    "    for j in range(preds.shape[0]):\n",
    "        temp = []\n",
    "        for k in preds[j, :]:\n",
    "            #k = k - 1\n",
    "            if k == len(lbl_enc.classes_):\n",
    "                temp.append(\"§\")\n",
    "            else:\n",
    "                p = encoder.inverse_transform([k])[0]\n",
    "                temp.append(p)\n",
    "        tp = \"\".join(temp).replace(\"§\", \"\")\n",
    "        cap_preds.append(remove_duplicates(tp))\n",
    "    return cap_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "4e60afeef02844ec904fe82af0b4ea7f",
      "10d0ab9ac63e4446bee53f44d87aa94c",
      "0b55451656814ebf8636181aa777f07f",
      "23cfbe5a2bdb4685a01e97a1672c57bb",
      "ae82d86babaf406b8ea131b4b8848def",
      "e65bf6cd419243e09a00b9f98f8fc015",
      "ba91dcb8029f4bda9aa99bc153775dff",
      "3cdab47ebdcf4e9280194fd46c40b005"
     ]
    },
    "colab_type": "code",
    "id": "DWnhEbviBSu7",
    "outputId": "f61edfbe-be20-43c4-ec41-8a4a4149f299"
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "model = ASRModel(num_chars=len(lbl_enc.classes_))\n",
    "model.to('cuda')\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-3)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, factor=0.8, patience=5, verbose=False\n",
    ")\n",
    "opt_level = 'O1'\n",
    "model, optimizer = amp.initialize(model, optimizer, opt_level=opt_level)\n",
    "\n",
    "for epoch in range(500):\n",
    "    train_loss = train_fn(model, train_loader, optimizer)\n",
    "    valid_preds, test_loss = eval_fn(model, test_loader)\n",
    "    \n",
    "    #valid_preds, test_loss = engine.eval_fn(model, test_loader)\n",
    "    valid_captcha_preds = []\n",
    "    for vp in valid_preds:\n",
    "        current_preds = decode_predictions(vp, lbl_enc)\n",
    "        valid_captcha_preds.extend(current_preds)\n",
    "    \n",
    "    combined = list(zip(test_targets_orig, valid_captcha_preds))\n",
    "    for dt in combined[:3]: \n",
    "        print(dt[0])\n",
    "        print(dt[1])\n",
    "    test_dup_rem = [remove_duplicates(c) for c in test_targets_orig]\n",
    "    accuracy = metrics.accuracy_score(test_dup_rem, valid_captcha_preds)\n",
    "    print(\n",
    "        f\"Epoch={epoch}, Train Loss={train_loss}, Test Loss={test_loss} Accuracy={accuracy}\"\n",
    "    )\n",
    "    \n",
    "    print(\n",
    "        f\"Epoch={epoch}, Train Loss={train_loss}, Test Loss={test_loss}\"\n",
    "    )\n",
    "    #scheduler.step(test_loss)\n",
    "    scheduler.step(train_loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GxHmlju3BSsr"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rCwu4xcSBSqZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "AUpW1dB9gwcZ",
    "outputId": "54cfe30b-7147-4b24-aad9-95d9b27e8ce0"
   },
   "outputs": [],
   "source": [
    "!pip install soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e8OBRd07ellz"
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "audio_files = glob(\"asr_bengali/data/*/*.flac\")\n",
    "\n",
    "import soundfile as sf  \n",
    "samples, sample_rate = sf.read(img_paths[0]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "tvZEeH_4h297",
    "outputId": "e0484ce2-a599-4b9d-ceec-ba805962f280"
   },
   "outputs": [],
   "source": [
    "print(type(samples))\n",
    "print(samples.shape)\n",
    "\n",
    "print(type(sample_rate))\n",
    "print(sample_rate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-I2c85FVgtYe"
   },
   "outputs": [],
   "source": [
    "def log_specgram(audio, sample_rate, window_size=20,\n",
    "                 step_size=10, eps=1e-10):\n",
    "    nperseg = int(round(window_size * sample_rate / 1e3))\n",
    "    noverlap = int(round(step_size * sample_rate / 1e3))\n",
    "    freqs, times, spec = signal.spectrogram(audio,\n",
    "                                    fs=sample_rate,\n",
    "                                    window='hann',\n",
    "                                    nperseg=nperseg,\n",
    "                                    noverlap=noverlap,\n",
    "                                    detrend=False)\n",
    "    return freqs, times, np.log(spec.T.astype(np.float32) + eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IAm73Iz46dYl"
   },
   "outputs": [],
   "source": [
    "freqs, times, spectrogram = log_specgram(samples, sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "f8ayWSlI6f5-",
    "outputId": "84a737a0-ae25-4d8d-e9dd-c3a9696e065b"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from PIL import ImageFile\n",
    "import albumentations\n",
    "mean = (0.485, 0.456, 0.406)\n",
    "std = (0.229, 0.224, 0.225)\n",
    "\n",
    "aug = albumentations.Compose(\n",
    "            [\n",
    "                albumentations.Normalize(\n",
    "                    mean, std, max_pixel_value=255.0, always_apply=True\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "\n",
    "print(type(spectrogram))\n",
    "print(spectrogram.shape)\n",
    "img = Image.fromarray( spectrogram , 'L')#.convert(\"RGB\")\n",
    "#img.show()\n",
    "\n",
    "image = img.resize(\n",
    "                (100, 300), resample=Image.BILINEAR\n",
    "            )\n",
    "\n",
    "image = np.array(image)\n",
    "augmented = aug(image=image)\n",
    "image = augmented[\"image\"]\n",
    "image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 504
    },
    "colab_type": "code",
    "id": "EFVdz6A4g0Df",
    "outputId": "20b34d28-7c20-4dbe-ccb5-1bb9832c6bd5"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "samples, sample_rate = sf.read(audio_files[100])\n",
    "freqs, times, spectrogram = log_specgram(samples, sample_rate)\n",
    "\n",
    "fig = plt.figure(figsize=(14, 8))\n",
    "ax1 = fig.add_subplot(211)\n",
    "#ax1.set_title('Raw wave of ' + filename)\n",
    "ax1.set_ylabel('Amplitude')\n",
    "#ax1.plot(np.linspace(0, sample_rate/len(samples), sample_rate), samples)\n",
    "\n",
    "ax2 = fig.add_subplot(212)\n",
    "ax2.imshow(spectrogram.T, aspect='auto', origin='lower', \n",
    "           extent=[times.min(), times.max(), freqs.min(), freqs.max()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "PizKrywAhFDy",
    "outputId": "e2441ab8-b02d-438c-d401-7136001112c3"
   },
   "outputs": [],
   "source": [
    "np.linspace(0, sample_rate/len(samples)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0cpccrlEjPRD",
    "outputId": "4b6188a9-11f2-4726-c991-754305fe3e36"
   },
   "outputs": [],
   "source": [
    "samples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "u13xjE6DjdK9",
    "outputId": "692ffbf4-896f-4eb3-b28c-91c491b65536"
   },
   "outputs": [],
   "source": [
    "spectrogram.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "62Mva-IcoypR",
    "outputId": "d4533cc1-1b84-40c1-cfa4-94f22779d8c8"
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class BeamEntry:\n",
    "\t\"information about one single beam at specific time-step\"\n",
    "\tdef __init__(self):\n",
    "\t\tself.prTotal = 0 # blank and non-blank\n",
    "\t\tself.prNonBlank = 0 # non-blank\n",
    "\t\tself.prBlank = 0 # blank\n",
    "\t\tself.prText = 1 # LM score\n",
    "\t\tself.lmApplied = False # flag if LM was already applied to this beam\n",
    "\t\tself.labeling = () # beam-labeling\n",
    "\n",
    "\n",
    "class BeamState:\n",
    "\t\"information about the beams at specific time-step\"\n",
    "\tdef __init__(self):\n",
    "\t\tself.entries = {}\n",
    "\n",
    "\tdef norm(self):\n",
    "\t\t\"length-normalise LM score\"\n",
    "\t\tfor (k, _) in self.entries.items():\n",
    "\t\t\tlabelingLen = len(self.entries[k].labeling)\n",
    "\t\t\tself.entries[k].prText = self.entries[k].prText ** (1.0 / (labelingLen if labelingLen else 1.0))\n",
    "\n",
    "\tdef sort(self):\n",
    "\t\t\"return beam-labelings, sorted by probability\"\n",
    "\t\tbeams = [v for (_, v) in self.entries.items()]\n",
    "\t\tsortedBeams = sorted(beams, reverse=True, key=lambda x: x.prTotal*x.prText)\n",
    "\t\treturn [x.labeling for x in sortedBeams]\n",
    "\n",
    "\n",
    "def applyLM(parentBeam, childBeam, classes, lm):\n",
    "\t\"calculate LM score of child beam by taking score from parent beam and bigram probability of last two chars\"\n",
    "\tif lm and not childBeam.lmApplied:\n",
    "\t\tc1 = classes[parentBeam.labeling[-1] if parentBeam.labeling else classes.index(' ')] # first char\n",
    "\t\tc2 = classes[childBeam.labeling[-1]] # second char\n",
    "\t\tlmFactor = 0.01 # influence of language model\n",
    "\t\tbigramProb = lm.getCharBigram(c1, c2) ** lmFactor # probability of seeing first and second char next to each other\n",
    "\t\tchildBeam.prText = parentBeam.prText * bigramProb # probability of char sequence\n",
    "\t\tchildBeam.lmApplied = True # only apply LM once per beam entry\n",
    "\n",
    "\n",
    "def addBeam(beamState, labeling):\n",
    "\t\"add beam if it does not yet exist\"\n",
    "\tif labeling not in beamState.entries:\n",
    "\t\tbeamState.entries[labeling] = BeamEntry()\n",
    "\n",
    "\n",
    "def ctcBeamSearch(mat, classes, lm, beamWidth=25):\n",
    "\t\"beam search as described by the paper of Hwang et al. and the paper of Graves et al.\"\n",
    "\n",
    "\tblankIdx = len(classes)\n",
    "\tmaxT, maxC = mat.shape\n",
    "\n",
    "\t# initialise beam state\n",
    "\tlast = BeamState()\n",
    "\tlabeling = ()\n",
    "\tlast.entries[labeling] = BeamEntry()\n",
    "\tlast.entries[labeling].prBlank = 1\n",
    "\tlast.entries[labeling].prTotal = 1\n",
    "\n",
    "\t# go over all time-steps\n",
    "\tfor t in range(maxT):\n",
    "\t\tcurr = BeamState()\n",
    "\n",
    "\t\t# get beam-labelings of best beams\n",
    "\t\tbestLabelings = last.sort()[0:beamWidth]\n",
    "\n",
    "\t\t# go over best beams\n",
    "\t\tfor labeling in bestLabelings:\n",
    "\n",
    "\t\t\t# probability of paths ending with a non-blank\n",
    "\t\t\tprNonBlank = 0\n",
    "\t\t\t# in case of non-empty beam\n",
    "\t\t\tif labeling:\n",
    "\t\t\t\t# probability of paths with repeated last char at the end\n",
    "\t\t\t\tprNonBlank = last.entries[labeling].prNonBlank * mat[t, labeling[-1]]\n",
    "\n",
    "\t\t\t# probability of paths ending with a blank\n",
    "\t\t\tprBlank = (last.entries[labeling].prTotal) * mat[t, blankIdx]\n",
    "\n",
    "\t\t\t# add beam at current time-step if needed\n",
    "\t\t\taddBeam(curr, labeling)\n",
    "\n",
    "\t\t\t# fill in data\n",
    "\t\t\tcurr.entries[labeling].labeling = labeling\n",
    "\t\t\tcurr.entries[labeling].prNonBlank += prNonBlank\n",
    "\t\t\tcurr.entries[labeling].prBlank += prBlank\n",
    "\t\t\tcurr.entries[labeling].prTotal += prBlank + prNonBlank\n",
    "\t\t\tcurr.entries[labeling].prText = last.entries[labeling].prText # beam-labeling not changed, therefore also LM score unchanged from\n",
    "\t\t\tcurr.entries[labeling].lmApplied = True # LM already applied at previous time-step for this beam-labeling\n",
    "\n",
    "\t\t\t# extend current beam-labeling\n",
    "\t\t\tfor c in range(maxC - 1):\n",
    "\t\t\t\t# add new char to current beam-labeling\n",
    "\t\t\t\tnewLabeling = labeling + (c,)\n",
    "\n",
    "\t\t\t\t# if new labeling contains duplicate char at the end, only consider paths ending with a blank\n",
    "\t\t\t\tif labeling and labeling[-1] == c:\n",
    "\t\t\t\t\tprNonBlank = mat[t, c] * last.entries[labeling].prBlank\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tprNonBlank = mat[t, c] * last.entries[labeling].prTotal\n",
    "\n",
    "\t\t\t\t# add beam at current time-step if needed\n",
    "\t\t\t\taddBeam(curr, newLabeling)\n",
    "\t\t\t\t\n",
    "\t\t\t\t# fill in data\n",
    "\t\t\t\tcurr.entries[newLabeling].labeling = newLabeling\n",
    "\t\t\t\tcurr.entries[newLabeling].prNonBlank += prNonBlank\n",
    "\t\t\t\tcurr.entries[newLabeling].prTotal += prNonBlank\n",
    "\t\t\t\t\n",
    "\t\t\t\t# apply LM\n",
    "\t\t\t\tapplyLM(curr.entries[labeling], curr.entries[newLabeling], classes, lm)\n",
    "\n",
    "\t\t# set new beam state\n",
    "\t\tlast = curr\n",
    "\n",
    "\t# normalise LM scores according to beam-labeling-length\n",
    "\tlast.norm()\n",
    "\n",
    "\t # sort by probability\n",
    "\tbestLabeling = last.sort()[0] # get most probable labeling\n",
    "\n",
    "\t# map labels to chars\n",
    "\tres = ''\n",
    "\tfor l in bestLabeling:\n",
    "\t\tres += classes[l]\n",
    "\n",
    "\treturn res\n",
    "\n",
    "def testBeamSearch():\n",
    "    classes = 'ab'\n",
    "    mat = np.array([[0.4, 0, 0.6], [0.4, 0, 0.6]])\n",
    "    print(mat.shape)\n",
    "    print('Test beam search')\n",
    "    expected = 'a'\n",
    "    actual = ctcBeamSearch(mat, classes, None)\n",
    "    print('Expected: \"' + expected + '\"')\n",
    "    print('Actual: \"' + actual + '\"')\n",
    "    print('OK' if expected == actual else 'ERROR')\n",
    "\n",
    "\n",
    "testBeamSearch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "58435d4773e749b9a76a88100a94d632",
      "fe61859218ac4da1831821af6880c3fc",
      "b002a95c48e1445288563a475ba3e83f",
      "37c6f5668d6b45a49874e44824af1875",
      "f20e3bca84014bb79cb788a159a94e17",
      "fc87e42dddfa4c1c848b1f27b225a810",
      "19786c258b90482b824c8d3ab474e965",
      "03d7701e0b0a4d7482afe4e643d4a817"
     ]
    },
    "colab_type": "code",
    "id": "lD6F31IZuhbM",
    "outputId": "3c78b386-cb9f-40c7-a3e1-63a428421026"
   },
   "outputs": [],
   "source": [
    "tk0 = tqdm(train_loader, total=len(train_loader))\n",
    "for data in tk0:\n",
    "    for key, value in data.items():\n",
    "        print(key)\n",
    "        print(value.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uHKH0c6o3oIW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "asr_bangla.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "03d7701e0b0a4d7482afe4e643d4a817": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0b55451656814ebf8636181aa777f07f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": " 46%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e65bf6cd419243e09a00b9f98f8fc015",
      "max": 993,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ae82d86babaf406b8ea131b4b8848def",
      "value": 456
     }
    },
    "10d0ab9ac63e4446bee53f44d87aa94c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "184d0db66ccc4e3e9c1bad1627d905b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ee34d2d990674dc493c371cd539c4d87",
      "max": 127565,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_26a5cf89a6ee421693847c4b94b16d91",
      "value": 127565
     }
    },
    "19786c258b90482b824c8d3ab474e965": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "23cfbe5a2bdb4685a01e97a1672c57bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3cdab47ebdcf4e9280194fd46c40b005",
      "placeholder": "​",
      "style": "IPY_MODEL_ba91dcb8029f4bda9aa99bc153775dff",
      "value": " 456/993 [17:59&lt;09:59,  1.12s/it]"
     }
    },
    "26a5cf89a6ee421693847c4b94b16d91": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "323ff2342e3843ada30bb9ae5f07098b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "37c6f5668d6b45a49874e44824af1875": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_03d7701e0b0a4d7482afe4e643d4a817",
      "placeholder": "​",
      "style": "IPY_MODEL_19786c258b90482b824c8d3ab474e965",
      "value": " 98/1194 [00:15&lt;00:46, 23.56it/s]"
     }
    },
    "3cdab47ebdcf4e9280194fd46c40b005": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4e60afeef02844ec904fe82af0b4ea7f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0b55451656814ebf8636181aa777f07f",
       "IPY_MODEL_23cfbe5a2bdb4685a01e97a1672c57bb"
      ],
      "layout": "IPY_MODEL_10d0ab9ac63e4446bee53f44d87aa94c"
     }
    },
    "58435d4773e749b9a76a88100a94d632": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b002a95c48e1445288563a475ba3e83f",
       "IPY_MODEL_37c6f5668d6b45a49874e44824af1875"
      ],
      "layout": "IPY_MODEL_fe61859218ac4da1831821af6880c3fc"
     }
    },
    "7904ddfb5f4749ab936c54d96dfc9c1d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9a11aa20369644e6a9d665ea1e453b00": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_184d0db66ccc4e3e9c1bad1627d905b3",
       "IPY_MODEL_a5c924ac95d24ce893e4e5487c9f3211"
      ],
      "layout": "IPY_MODEL_9f0ca46e517b4bceb75b031cd3787dab"
     }
    },
    "9f0ca46e517b4bceb75b031cd3787dab": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a5c924ac95d24ce893e4e5487c9f3211": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_323ff2342e3843ada30bb9ae5f07098b",
      "placeholder": "​",
      "style": "IPY_MODEL_7904ddfb5f4749ab936c54d96dfc9c1d",
      "value": " 127565/127565 [00:56&lt;00:00, 2257.93it/s]"
     }
    },
    "ae82d86babaf406b8ea131b4b8848def": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "b002a95c48e1445288563a475ba3e83f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "  8%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fc87e42dddfa4c1c848b1f27b225a810",
      "max": 1194,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f20e3bca84014bb79cb788a159a94e17",
      "value": 98
     }
    },
    "ba91dcb8029f4bda9aa99bc153775dff": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e65bf6cd419243e09a00b9f98f8fc015": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ee34d2d990674dc493c371cd539c4d87": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f20e3bca84014bb79cb788a159a94e17": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "fc87e42dddfa4c1c848b1f27b225a810": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fe61859218ac4da1831821af6880c3fc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
